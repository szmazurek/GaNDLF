device = 'cpu'

    def test_train_segmentation_rad_2d(device):
        print("03: Starting 2D Rad segmentation tests")
        # read and parse csv
        parameters = parseConfigGAN(
            testingDir + "/config_generation.yaml", version_check_flag=False
        )
        training_data, parameters["headers"] = parseTrainingCSV(
            inputDir + "/train_2d_rad_segmentation.csv"
        )
        parameters["modality"] = "rad"
        parameters["patch_size"] = patch_size["2D"]
        parameters["model"]["dimension"] = 2
        parameters["model"]["class_list"] = [0, 255]
        parameters["model"]["amp"] = True
        parameters["model"]["num_channels"] = 3
        parameters["model"]["onnx_export"] = False
        parameters["model"]["print_summary"] = False
        parameters["data_preprocessing"]["resize_image"] = [224, 224]
        parameters = populate_header_in_parameters(
            parameters, parameters["headers"]
        )
        # read and initialize parameters for specific data dimension
        for model in all_models_generation:
            parameters["model"]["architecture"] = model
            parameters["nested_training"]["testing"] = -5
            parameters["nested_training"]["validation"] = -5
            sanitize_outputDir()
>           TrainingManagerGAN(
                dataframe=training_data,
                outputDir=outputDir,
                parameters=parameters,
                device=device,
                resume=False,
                reset=True,
            )

GANDLF/GAN/testing/test_gan.py:80: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
../venvs/gandalf_env/lib/python3.10/site-packages/GANDLF/GAN/training_manager_gan.py:270: in TrainingManagerGAN
    training_loop_gans(
../venvs/gandalf_env/lib/python3.10/site-packages/GANDLF/GAN/compute/training_loop.py:513: in training_loop_gans
    ) = train_network_gan(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

model = DCGAN(
  (generator): _GneratorDCGAN(
    (feature_extractor): Sequential(
      (conv1t): ConvTranspose2d(100, 4, ker...nplace=True)
      (linear2): Linear(in_features=128, out_features=1, bias=True)
      (sigmoid): Sigmoid()
    )
  )
)
train_dataloader = <torch.utils.data.dataloader.DataLoader object at 0x7f14052cbe50>
optimizer_g = Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
  ...-08
    foreach: None
    fused: None
    initial_lr: 0.001
    lr: 0.001
    maximize: False
    weight_decay: 5e-05
)
optimizer_d = Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
  ...-08
    foreach: None
    fused: None
    initial_lr: 0.001
    lr: 0.001
    maximize: False
    weight_decay: 5e-05
)
params = {'batch_size': 1, 'bn_size': 4, 'channel_keys': ['1'], 'class_weights': None, ...}

    def train_network_gan(
        model, train_dataloader, optimizer_g, optimizer_d, params
    ):
        """
        Function to train a GAN network for a single epoch.
        This function is a modified version of train_network() to support
        usage of two optimizers for the generator and discriminator.
    
        Parameters
        ----------
        model : torch.model
            The model to process the input image with, it should support appropriate dimensions.
        train_dataloader : torch.DataLoader
            The dataloader for the training epoch
        optimizer_g : torch.optim
            Optimizer for optimizing generator network
        optimizer_d : torch.optim
            Optimizer for optimizing discriminator network
        params : dict
            the parameters passed by the user yaml
    
        Returns
        -------
        average_epoch_train_loss_gen : float
            Train loss for the current epoch for generator
        average_epoch_train_loss_disc : float
            Train loss for the current epoch for discriminator
        average_epoch_train_metric : dict
            Train metrics for the current epoch
        """
    
        print("*" * 20)
        print("Starting Training : ")
        print("*" * 20)
        # Initialize a few things
        total_epoch_train_loss_gen = 0
        total_epoch_train_loss_disc = 0
        total_epoch_train_metric = {}
        average_epoch_train_metric = {}
        for metric in params["metrics"]:
            if "per_label" in metric:  # conditional generation not yet implemented
                total_epoch_train_metric[metric] = []
            else:
                total_epoch_train_metric[metric] = 0
    
        # automatic mixed precision - https://pytorch.org/docs/stable/amp.html
        if params["model"]["amp"]:
            scaler = GradScaler()
            if params["verbose"]:
                print("Using Automatic mixed precision", flush=True)
    
        # Set the model to train
        model.train()
        for batch_idx, (subject) in enumerate(
            tqdm(train_dataloader, desc="Looping over training data")
        ):
            #### DISCRIMINATOR STEP WITH ALL REAL LABELS ####
            optimizer_d.zero_grad()
            image_real = (
                torch.cat(
                    [subject[key][torchio.DATA] for key in params["channel_keys"]],
                    dim=1,
                )
                .float()
                .to(params["device"])
            )
            current_batch_size = image_real.shape[0]
    
>           label_real = torch.full(
                current_batch_size,
                1,
                dtype=torch.float,
                device=params["device"],
            )
E           TypeError: full() received an invalid combination of arguments - got (int, int, device=torch.device, dtype=torch.dtype), but expected one of:
E            * (tuple of ints size, Number fill_value, *, tuple of names names, torch.dtype dtype, torch.layout layout, torch.device device, bool pin_memory, bool requires_grad)
E            * (tuple of ints size, Number fill_value, *, Tensor out, torch.dtype dtype, torch.layout layout, torch.device device, bool pin_memory, bool requires_grad)

../venvs/gandalf_env/lib/python3.10/site-packages/GANDLF/GAN/compute/training_loop.py:106: TypeError
device = 'cpu'

    def test_train_segmentation_rad_2d(device):
        print("03: Starting 2D Rad segmentation tests")
        # read and parse csv
        parameters = parseConfigGAN(
            testingDir + "/config_generation.yaml", version_check_flag=False
        )
        training_data, parameters["headers"] = parseTrainingCSV(
            inputDir + "/train_2d_rad_segmentation.csv"
        )
        parameters["modality"] = "rad"
        parameters["patch_size"] = patch_size["2D"]
        parameters["model"]["dimension"] = 2
        parameters["model"]["class_list"] = [0, 255]
        parameters["model"]["amp"] = True
        parameters["model"]["num_channels"] = 3
        parameters["model"]["onnx_export"] = False
        parameters["model"]["print_summary"] = False
        parameters["data_preprocessing"]["resize_image"] = [224, 224]
        parameters = populate_header_in_parameters(
            parameters, parameters["headers"]
        )
        # read and initialize parameters for specific data dimension
        for model in all_models_generation:
            parameters["model"]["architecture"] = model
            parameters["nested_training"]["testing"] = -5
            parameters["nested_training"]["validation"] = -5
            sanitize_outputDir()
>           TrainingManagerGAN(
                dataframe=training_data,
                outputDir=outputDir,
                parameters=parameters,
                device=device,
                resume=False,
                reset=True,
            )

GANDLF/GAN/testing/test_gan.py:80: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
../venvs/gandalf_env/lib/python3.10/site-packages/GANDLF/GAN/training_manager_gan.py:270: in TrainingManagerGAN
    training_loop_gans(
../venvs/gandalf_env/lib/python3.10/site-packages/GANDLF/GAN/compute/training_loop.py:511: in training_loop_gans
    ) = train_network_gan(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

model = DCGAN(
  (generator): _GneratorDCGAN(
    (feature_extractor): Sequential(
      (conv1t): ConvTranspose2d(100, 4, ker...nplace=True)
      (linear2): Linear(in_features=128, out_features=1, bias=True)
      (sigmoid): Sigmoid()
    )
  )
)
train_dataloader = <torch.utils.data.dataloader.DataLoader object at 0x7f3397f9fe20>
optimizer_g = Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
  ...-08
    foreach: None
    fused: None
    initial_lr: 0.001
    lr: 0.001
    maximize: False
    weight_decay: 5e-05
)
optimizer_d = Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
  ...-08
    foreach: None
    fused: None
    initial_lr: 0.001
    lr: 0.001
    maximize: False
    weight_decay: 5e-05
)
params = {'batch_size': 1, 'bn_size': 4, 'channel_keys': ['1'], 'class_weights': None, ...}

    def train_network_gan(
        model, train_dataloader, optimizer_g, optimizer_d, params
    ):
        """
        Function to train a GAN network for a single epoch.
        This function is a modified version of train_network() to support
        usage of two optimizers for the generator and discriminator.
    
        Parameters
        ----------
        model : torch.model
            The model to process the input image with, it should support appropriate dimensions.
        train_dataloader : torch.DataLoader
            The dataloader for the training epoch
        optimizer_g : torch.optim
            Optimizer for optimizing generator network
        optimizer_d : torch.optim
            Optimizer for optimizing discriminator network
        params : dict
            the parameters passed by the user yaml
    
        Returns
        -------
        average_epoch_train_loss_gen : float
            Train loss for the current epoch for generator
        average_epoch_train_loss_disc : float
            Train loss for the current epoch for discriminator
        average_epoch_train_metric : dict
            Train metrics for the current epoch
        """
    
        print("*" * 20)
        print("Starting Training : ")
        print("*" * 20)
        # Initialize a few things
        total_epoch_train_loss_gen = 0
        total_epoch_train_loss_disc = 0
        total_epoch_train_metric = {}
        average_epoch_train_metric = {}
        for metric in params["metrics"]:
            if "per_label" in metric:  # conditional generation not yet implemented
                total_epoch_train_metric[metric] = []
            else:
                total_epoch_train_metric[metric] = 0
    
        # automatic mixed precision - https://pytorch.org/docs/stable/amp.html
        if params["model"]["amp"]:
            scaler = GradScaler()
            if params["verbose"]:
                print("Using Automatic mixed precision", flush=True)
    
        # Set the model to train
        model.train()
        for batch_idx, (subject) in enumerate(
            tqdm(train_dataloader, desc="Looping over training data")
        ):
            #### DISCRIMINATOR STEP WITH ALL REAL LABELS ####
            optimizer_d.zero_grad()
            image_real = (
                torch.cat(
                    [subject[key][torchio.DATA] for key in params["channel_keys"]],
                    dim=1,
                )
                .float()
                .to(params["device"])
            )
            current_batch_size = image_real.shape[0]
    
>           label_real = torch.full(
                size=current_batch_size,
                fill_value=1,
                dtype=torch.float,
                device=params["device"],
            )
E           TypeError: full() received an invalid combination of arguments - got (device=torch.device, dtype=torch.dtype, fill_value=int, size=int, ), but expected one of:
E            * (tuple of ints size, Number fill_value, *, tuple of names names, torch.dtype dtype, torch.layout layout, torch.device device, bool pin_memory, bool requires_grad)
E            * (tuple of ints size, Number fill_value, *, Tensor out, torch.dtype dtype, torch.layout layout, torch.device device, bool pin_memory, bool requires_grad)

../venvs/gandalf_env/lib/python3.10/site-packages/GANDLF/GAN/compute/training_loop.py:106: TypeError
device = 'cpu'

    def test_train_segmentation_rad_2d(device):
        print("03: Starting 2D Rad segmentation tests")
        # read and parse csv
        parameters = parseConfigGAN(
            testingDir + "/config_generation.yaml", version_check_flag=False
        )
        training_data, parameters["headers"] = parseTrainingCSV(
            inputDir + "/train_2d_rad_segmentation.csv"
        )
        parameters["modality"] = "rad"
        parameters["patch_size"] = patch_size["2D"]
        parameters["model"]["dimension"] = 2
        parameters["model"]["class_list"] = [0, 255]
        parameters["model"]["amp"] = True
        parameters["model"]["num_channels"] = 3
        parameters["model"]["onnx_export"] = False
        parameters["model"]["print_summary"] = False
        parameters["data_preprocessing"]["resize_image"] = [224, 224]
        parameters = populate_header_in_parameters(
            parameters, parameters["headers"]
        )
        # read and initialize parameters for specific data dimension
        for model in all_models_generation:
            parameters["model"]["architecture"] = model
            parameters["nested_training"]["testing"] = -5
            parameters["nested_training"]["validation"] = -5
            sanitize_outputDir()
>           TrainingManagerGAN(
                dataframe=training_data,
                outputDir=outputDir,
                parameters=parameters,
                device=device,
                resume=False,
                reset=True,
            )

GANDLF/GAN/testing/test_gan.py:80: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
../venvs/gandalf_env/lib/python3.10/site-packages/GANDLF/GAN/training_manager_gan.py:270: in TrainingManagerGAN
    training_loop_gans(
../venvs/gandalf_env/lib/python3.10/site-packages/GANDLF/GAN/compute/training_loop.py:512: in training_loop_gans
    ) = train_network_gan(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

model = DCGAN(
  (generator): _GneratorDCGAN(
    (feature_extractor): Sequential(
      (conv1t): ConvTranspose2d(100, 4, ker...nplace=True)
      (linear2): Linear(in_features=128, out_features=1, bias=True)
      (sigmoid): Sigmoid()
    )
  )
)
train_dataloader = <torch.utils.data.dataloader.DataLoader object at 0x7fa589ec3ca0>
optimizer_g = Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
  ...-08
    foreach: None
    fused: None
    initial_lr: 0.001
    lr: 0.001
    maximize: False
    weight_decay: 5e-05
)
optimizer_d = Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
  ...-08
    foreach: None
    fused: None
    initial_lr: 0.001
    lr: 0.001
    maximize: False
    weight_decay: 5e-05
)
params = {'batch_size': 1, 'bn_size': 4, 'channel_keys': ['1'], 'class_weights': None, ...}

    def train_network_gan(
        model, train_dataloader, optimizer_g, optimizer_d, params
    ):
        """
        Function to train a GAN network for a single epoch.
        This function is a modified version of train_network() to support
        usage of two optimizers for the generator and discriminator.
    
        Parameters
        ----------
        model : torch.model
            The model to process the input image with, it should support appropriate dimensions.
        train_dataloader : torch.DataLoader
            The dataloader for the training epoch
        optimizer_g : torch.optim
            Optimizer for optimizing generator network
        optimizer_d : torch.optim
            Optimizer for optimizing discriminator network
        params : dict
            the parameters passed by the user yaml
    
        Returns
        -------
        average_epoch_train_loss_gen : float
            Train loss for the current epoch for generator
        average_epoch_train_loss_disc : float
            Train loss for the current epoch for discriminator
        average_epoch_train_metric : dict
            Train metrics for the current epoch
        """
    
        print("*" * 20)
        print("Starting Training : ")
        print("*" * 20)
        # Initialize a few things
        total_epoch_train_loss_gen = 0
        total_epoch_train_loss_disc = 0
        total_epoch_train_metric = {}
        average_epoch_train_metric = {}
        for metric in params["metrics"]:
            if "per_label" in metric:  # conditional generation not yet implemented
                total_epoch_train_metric[metric] = []
            else:
                total_epoch_train_metric[metric] = 0
    
        # automatic mixed precision - https://pytorch.org/docs/stable/amp.html
        if params["model"]["amp"]:
            scaler = GradScaler()
            if params["verbose"]:
                print("Using Automatic mixed precision", flush=True)
    
        # Set the model to train
        model.train()
        for batch_idx, (subject) in enumerate(
            tqdm(train_dataloader, desc="Looping over training data")
        ):
            #### DISCRIMINATOR STEP WITH ALL REAL LABELS ####
            optimizer_d.zero_grad()
            image_real = (
                torch.cat(
                    [subject[key][torchio.DATA] for key in params["channel_keys"]],
                    dim=1,
                )
                .float()
                .to(params["device"])
            )
            current_batch_size = image_real.shape[0]
            print("Current batch size : ", current_batch_size)
            print("device : ", params["device"])
>           label_real = torch.full(
                size=current_batch_size,
                fill_value=1,
                dtype=torch.float,
                device=params["device"],
            )
E           TypeError: full() received an invalid combination of arguments - got (device=torch.device, dtype=torch.dtype, fill_value=int, size=int, ), but expected one of:
E            * (tuple of ints size, Number fill_value, *, tuple of names names, torch.dtype dtype, torch.layout layout, torch.device device, bool pin_memory, bool requires_grad)
E            * (tuple of ints size, Number fill_value, *, Tensor out, torch.dtype dtype, torch.layout layout, torch.device device, bool pin_memory, bool requires_grad)

../venvs/gandalf_env/lib/python3.10/site-packages/GANDLF/GAN/compute/training_loop.py:107: TypeError
device = 'cpu'

    def test_train_segmentation_rad_2d(device):
        print("03: Starting 2D Rad segmentation tests")
        # read and parse csv
        parameters = parseConfigGAN(
            testingDir + "/config_generation.yaml", version_check_flag=False
        )
        training_data, parameters["headers"] = parseTrainingCSV(
            inputDir + "/train_2d_rad_segmentation.csv"
        )
        parameters["modality"] = "rad"
        parameters["patch_size"] = patch_size["2D"]
        parameters["model"]["dimension"] = 2
        parameters["model"]["class_list"] = [0, 255]
        parameters["model"]["amp"] = True
        parameters["model"]["num_channels"] = 3
        parameters["model"]["onnx_export"] = False
        parameters["model"]["print_summary"] = False
        parameters["data_preprocessing"]["resize_image"] = [224, 224]
        parameters = populate_header_in_parameters(
            parameters, parameters["headers"]
        )
        # read and initialize parameters for specific data dimension
        for model in all_models_generation:
            parameters["model"]["architecture"] = model
            parameters["nested_training"]["testing"] = -5
            parameters["nested_training"]["validation"] = -5
            sanitize_outputDir()
>           TrainingManagerGAN(
                dataframe=training_data,
                outputDir=outputDir,
                parameters=parameters,
                device=device,
                resume=False,
                reset=True,
            )

GANDLF/GAN/testing/test_gan.py:80: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
../venvs/gandalf_env/lib/python3.10/site-packages/GANDLF/GAN/training_manager_gan.py:270: in TrainingManagerGAN
    training_loop_gans(
../venvs/gandalf_env/lib/python3.10/site-packages/GANDLF/GAN/compute/training_loop.py:512: in training_loop_gans
    ) = train_network_gan(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

model = DCGAN(
  (generator): _GneratorDCGAN(
    (feature_extractor): Sequential(
      (conv1t): ConvTranspose2d(100, 4, ker...nplace=True)
      (linear2): Linear(in_features=128, out_features=1, bias=True)
      (sigmoid): Sigmoid()
    )
  )
)
train_dataloader = <torch.utils.data.dataloader.DataLoader object at 0x7f0a7c9bba90>
optimizer_g = Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
  ...-08
    foreach: None
    fused: None
    initial_lr: 0.001
    lr: 0.001
    maximize: False
    weight_decay: 5e-05
)
optimizer_d = Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
  ...-08
    foreach: None
    fused: None
    initial_lr: 0.001
    lr: 0.001
    maximize: False
    weight_decay: 5e-05
)
params = {'batch_size': 1, 'bn_size': 4, 'channel_keys': ['1'], 'class_weights': None, ...}

    def train_network_gan(
        model, train_dataloader, optimizer_g, optimizer_d, params
    ):
        """
        Function to train a GAN network for a single epoch.
        This function is a modified version of train_network() to support
        usage of two optimizers for the generator and discriminator.
    
        Parameters
        ----------
        model : torch.model
            The model to process the input image with, it should support appropriate dimensions.
        train_dataloader : torch.DataLoader
            The dataloader for the training epoch
        optimizer_g : torch.optim
            Optimizer for optimizing generator network
        optimizer_d : torch.optim
            Optimizer for optimizing discriminator network
        params : dict
            the parameters passed by the user yaml
    
        Returns
        -------
        average_epoch_train_loss_gen : float
            Train loss for the current epoch for generator
        average_epoch_train_loss_disc : float
            Train loss for the current epoch for discriminator
        average_epoch_train_metric : dict
            Train metrics for the current epoch
        """
    
        print("*" * 20)
        print("Starting Training : ")
        print("*" * 20)
        # Initialize a few things
        total_epoch_train_loss_gen = 0
        total_epoch_train_loss_disc = 0
        total_epoch_train_metric = {}
        average_epoch_train_metric = {}
        for metric in params["metrics"]:
            if "per_label" in metric:  # conditional generation not yet implemented
                total_epoch_train_metric[metric] = []
            else:
                total_epoch_train_metric[metric] = 0
    
        # automatic mixed precision - https://pytorch.org/docs/stable/amp.html
        if params["model"]["amp"]:
            scaler = GradScaler()
            if params["verbose"]:
                print("Using Automatic mixed precision", flush=True)
    
        # Set the model to train
        model.train()
        for batch_idx, (subject) in enumerate(
            tqdm(train_dataloader, desc="Looping over training data")
        ):
            #### DISCRIMINATOR STEP WITH ALL REAL LABELS ####
            optimizer_d.zero_grad()
            image_real = (
                torch.cat(
                    [subject[key][torchio.DATA] for key in params["channel_keys"]],
                    dim=1,
                )
                .float()
                .to(params["device"])
            )
            current_batch_size = image_real.shape[0]
            print("Current batch size : ", current_batch_size)
            print("device : ", params["device"])
>           label_real = torch.full(
                size=current_batch_size,
                fill_value=1,
                dtype=torch.float,
                device=torch.device(params["device"]),
            )
E           TypeError: full() received an invalid combination of arguments - got (device=torch.device, dtype=torch.dtype, fill_value=int, size=int, ), but expected one of:
E            * (tuple of ints size, Number fill_value, *, tuple of names names, torch.dtype dtype, torch.layout layout, torch.device device, bool pin_memory, bool requires_grad)
E            * (tuple of ints size, Number fill_value, *, Tensor out, torch.dtype dtype, torch.layout layout, torch.device device, bool pin_memory, bool requires_grad)

../venvs/gandalf_env/lib/python3.10/site-packages/GANDLF/GAN/compute/training_loop.py:107: TypeError
device = 'cpu'

    def test_train_segmentation_rad_2d(device):
        print("03: Starting 2D Rad segmentation tests")
        # read and parse csv
        parameters = parseConfigGAN(
            testingDir + "/config_generation.yaml", version_check_flag=False
        )
        training_data, parameters["headers"] = parseTrainingCSV(
            inputDir + "/train_2d_rad_segmentation.csv"
        )
        parameters["modality"] = "rad"
        parameters["patch_size"] = patch_size["2D"]
        parameters["model"]["dimension"] = 2
        parameters["model"]["class_list"] = [0, 255]
        parameters["model"]["amp"] = True
        parameters["model"]["num_channels"] = 3
        parameters["model"]["onnx_export"] = False
        parameters["model"]["print_summary"] = False
        parameters["data_preprocessing"]["resize_image"] = [224, 224]
        parameters = populate_header_in_parameters(
            parameters, parameters["headers"]
        )
        # read and initialize parameters for specific data dimension
        for model in all_models_generation:
            parameters["model"]["architecture"] = model
            parameters["nested_training"]["testing"] = -5
            parameters["nested_training"]["validation"] = -5
            sanitize_outputDir()
>           TrainingManagerGAN(
                dataframe=training_data,
                outputDir=outputDir,
                parameters=parameters,
                device=device,
                resume=False,
                reset=True,
            )

GANDLF/GAN/testing/test_gan.py:80: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
../venvs/gandalf_env/lib/python3.10/site-packages/GANDLF/GAN/training_manager_gan.py:270: in TrainingManagerGAN
    training_loop_gans(
../venvs/gandalf_env/lib/python3.10/site-packages/GANDLF/GAN/compute/training_loop.py:512: in training_loop_gans
    ) = train_network_gan(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

model = DCGAN(
  (generator): _GneratorDCGAN(
    (feature_extractor): Sequential(
      (conv1t): ConvTranspose2d(100, 4, ker...nplace=True)
      (linear2): Linear(in_features=128, out_features=1, bias=True)
      (sigmoid): Sigmoid()
    )
  )
)
train_dataloader = <torch.utils.data.dataloader.DataLoader object at 0x7f06be1bfa90>
optimizer_g = Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
  ...-08
    foreach: None
    fused: None
    initial_lr: 0.001
    lr: 0.001
    maximize: False
    weight_decay: 5e-05
)
optimizer_d = Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
  ...-08
    foreach: None
    fused: None
    initial_lr: 0.001
    lr: 0.001
    maximize: False
    weight_decay: 5e-05
)
params = {'batch_size': 1, 'bn_size': 4, 'channel_keys': ['1'], 'class_weights': None, ...}

    def train_network_gan(
        model, train_dataloader, optimizer_g, optimizer_d, params
    ):
        """
        Function to train a GAN network for a single epoch.
        This function is a modified version of train_network() to support
        usage of two optimizers for the generator and discriminator.
    
        Parameters
        ----------
        model : torch.model
            The model to process the input image with, it should support appropriate dimensions.
        train_dataloader : torch.DataLoader
            The dataloader for the training epoch
        optimizer_g : torch.optim
            Optimizer for optimizing generator network
        optimizer_d : torch.optim
            Optimizer for optimizing discriminator network
        params : dict
            the parameters passed by the user yaml
    
        Returns
        -------
        average_epoch_train_loss_gen : float
            Train loss for the current epoch for generator
        average_epoch_train_loss_disc : float
            Train loss for the current epoch for discriminator
        average_epoch_train_metric : dict
            Train metrics for the current epoch
        """
    
        print("*" * 20)
        print("Starting Training : ")
        print("*" * 20)
        # Initialize a few things
        total_epoch_train_loss_gen = 0
        total_epoch_train_loss_disc = 0
        total_epoch_train_metric = {}
        average_epoch_train_metric = {}
        for metric in params["metrics"]:
            if "per_label" in metric:  # conditional generation not yet implemented
                total_epoch_train_metric[metric] = []
            else:
                total_epoch_train_metric[metric] = 0
    
        # automatic mixed precision - https://pytorch.org/docs/stable/amp.html
        if params["model"]["amp"]:
            scaler = GradScaler()
            if params["verbose"]:
                print("Using Automatic mixed precision", flush=True)
    
        # Set the model to train
        model.train()
        for batch_idx, (subject) in enumerate(
            tqdm(train_dataloader, desc="Looping over training data")
        ):
            #### DISCRIMINATOR STEP WITH ALL REAL LABELS ####
            optimizer_d.zero_grad()
            image_real = (
                torch.cat(
                    [subject[key][torchio.DATA] for key in params["channel_keys"]],
                    dim=1,
                )
                .float()
                .to(params["device"])
            )
            current_batch_size = image_real.shape[0]
            print("Current batch size : ", current_batch_size)
            print("device : ", params["device"])
>           label_real = torch.full(
                size=(current_batch_size),
                fill_value=1,
                dtype=torch.float,
                device=torch.device(params["device"]),
            )
E           TypeError: full() received an invalid combination of arguments - got (device=torch.device, dtype=torch.dtype, fill_value=int, size=int, ), but expected one of:
E            * (tuple of ints size, Number fill_value, *, tuple of names names, torch.dtype dtype, torch.layout layout, torch.device device, bool pin_memory, bool requires_grad)
E            * (tuple of ints size, Number fill_value, *, Tensor out, torch.dtype dtype, torch.layout layout, torch.device device, bool pin_memory, bool requires_grad)

../venvs/gandalf_env/lib/python3.10/site-packages/GANDLF/GAN/compute/training_loop.py:107: TypeError
device = 'cpu'

    def test_train_segmentation_rad_2d(device):
        print("03: Starting 2D Rad segmentation tests")
        # read and parse csv
        parameters = parseConfigGAN(
            testingDir + "/config_generation.yaml", version_check_flag=False
        )
        training_data, parameters["headers"] = parseTrainingCSV(
            inputDir + "/train_2d_rad_segmentation.csv"
        )
        parameters["modality"] = "rad"
        parameters["patch_size"] = patch_size["2D"]
        parameters["model"]["dimension"] = 2
        parameters["model"]["class_list"] = [0, 255]
        parameters["model"]["amp"] = True
        parameters["model"]["num_channels"] = 3
        parameters["model"]["onnx_export"] = False
        parameters["model"]["print_summary"] = False
        parameters["data_preprocessing"]["resize_image"] = [224, 224]
        parameters = populate_header_in_parameters(
            parameters, parameters["headers"]
        )
        # read and initialize parameters for specific data dimension
        for model in all_models_generation:
            parameters["model"]["architecture"] = model
            parameters["nested_training"]["testing"] = -5
            parameters["nested_training"]["validation"] = -5
            sanitize_outputDir()
>           TrainingManagerGAN(
                dataframe=training_data,
                outputDir=outputDir,
                parameters=parameters,
                device=device,
                resume=False,
                reset=True,
            )

GANDLF/GAN/testing/test_gan.py:80: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
../venvs/gandalf_env/lib/python3.10/site-packages/GANDLF/GAN/training_manager_gan.py:270: in TrainingManagerGAN
    training_loop_gans(
../venvs/gandalf_env/lib/python3.10/site-packages/GANDLF/GAN/compute/training_loop.py:512: in training_loop_gans
    ) = train_network_gan(
../venvs/gandalf_env/lib/python3.10/site-packages/GANDLF/GAN/compute/training_loop.py:124: in train_network_gan
    loss_disc_real, _, output_disc_real, _ = step_gan(
../venvs/gandalf_env/lib/python3.10/site-packages/GANDLF/GAN/compute/step.py:89: in step_gan
    loss, metric_output = get_loss_and_metrics_gans(
../venvs/gandalf_env/lib/python3.10/site-packages/GANDLF/GAN/compute/loss_and_metric.py:80: in get_loss_and_metrics_gans
    loss = get_loss_gans(predictions, labels, params)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

predictions = tensor([[0.4916]], grad_fn=<SigmoidBackward0>), labels = tensor([1.]), params = {'batch_size': 1, 'bn_size': 4, 'channel_keys': ['1'], 'class_weights': None, ...}

    def get_loss_gans(predictions: Tensor, labels: Tensor, params: dict) -> Tensor:
        """
        Compute the loss value for adversatial generative networks.
        Args:
            predictions (Tensor): The predicted output from the model.
            labels (Tensor): The ground truth label.
            params (dict): The parameters passed by the user yaml.
        Returns:
            loss (Tensor): The computed loss from the label and the prediction.
        """
    
        if isinstance(params["loss_function"], dict):
            # check for mse_torch
            loss_function = global_losses_dict[
                list(params["loss_function"].keys())[0]
            ]
        else:
            loss_str_lower = params["loss_function"].lower()
            if loss_str_lower in global_losses_dict:
                loss_function = global_losses_dict[loss_str_lower]
            else:
                sys.exit(
                    "WARNING: Could not find the requested loss function '"
                    + params["loss_function"]
                )
    
>       loss = loss_function(predictions, labels, params)
E       TypeError: CE() takes 2 positional arguments but 3 were given

../venvs/gandalf_env/lib/python3.10/site-packages/GANDLF/GAN/compute/loss_and_metric.py:53: TypeError
device = 'cpu'

    def test_train_segmentation_rad_2d(device):
        print("03: Starting 2D Rad segmentation tests")
        # read and parse csv
        parameters = parseConfigGAN(
            testingDir + "/config_generation.yaml", version_check_flag=False
        )
        training_data, parameters["headers"] = parseTrainingCSV(
            inputDir + "/train_2d_rad_segmentation.csv"
        )
        parameters["modality"] = "rad"
        parameters["patch_size"] = patch_size["2D"]
        parameters["model"]["dimension"] = 2
        parameters["model"]["class_list"] = [0, 255]
        parameters["model"]["amp"] = True
        parameters["model"]["num_channels"] = 3
        parameters["model"]["onnx_export"] = False
        parameters["model"]["print_summary"] = False
        parameters["data_preprocessing"]["resize_image"] = [224, 224]
        parameters = populate_header_in_parameters(
            parameters, parameters["headers"]
        )
        # read and initialize parameters for specific data dimension
        for model in all_models_generation:
            parameters["model"]["architecture"] = model
            parameters["nested_training"]["testing"] = -5
            parameters["nested_training"]["validation"] = -5
            sanitize_outputDir()
>           TrainingManagerGAN(
                dataframe=training_data,
                outputDir=outputDir,
                parameters=parameters,
                device=device,
                resume=False,
                reset=True,
            )

GANDLF/GAN/testing/test_gan.py:80: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
../venvs/gandalf_env/lib/python3.10/site-packages/GANDLF/GAN/training_manager_gan.py:270: in TrainingManagerGAN
    training_loop_gans(
../venvs/gandalf_env/lib/python3.10/site-packages/GANDLF/GAN/compute/training_loop.py:511: in training_loop_gans
    ) = train_network_gan(
../venvs/gandalf_env/lib/python3.10/site-packages/GANDLF/GAN/compute/training_loop.py:123: in train_network_gan
    loss_disc_real, _, output_disc_real, _ = step_gan(
../venvs/gandalf_env/lib/python3.10/site-packages/GANDLF/GAN/compute/step.py:89: in step_gan
    loss, metric_output = get_loss_and_metrics_gans(
../venvs/gandalf_env/lib/python3.10/site-packages/GANDLF/GAN/compute/loss_and_metric.py:80: in get_loss_and_metrics_gans
    loss = get_loss_gans(predictions, labels, params)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

predictions = tensor([[0.5843]], grad_fn=<SigmoidBackward0>), labels = tensor([1.]), params = {'batch_size': 1, 'bn_size': 4, 'channel_keys': ['1'], 'class_weights': None, ...}

    def get_loss_gans(predictions: Tensor, labels: Tensor, params: dict) -> Tensor:
        """
        Compute the loss value for adversatial generative networks.
        Args:
            predictions (Tensor): The predicted output from the model.
            labels (Tensor): The ground truth label.
            params (dict): The parameters passed by the user yaml.
        Returns:
            loss (Tensor): The computed loss from the label and the prediction.
        """
    
        if isinstance(params["loss_function"], dict):
            # check for mse_torch
            loss_function = global_losses_dict[
                list(params["loss_function"].keys())[0]
            ]
        else:
            loss_str_lower = params["loss_function"].lower()
            if loss_str_lower in global_losses_dict:
                loss_function = global_losses_dict[loss_str_lower]
            else:
                sys.exit(
                    "WARNING: Could not find the requested loss function '"
                    + params["loss_function"]
                )
    
>       loss = loss_function(predictions, labels, params)
E       TypeError: CE() takes 2 positional arguments but 3 were given

../venvs/gandalf_env/lib/python3.10/site-packages/GANDLF/GAN/compute/loss_and_metric.py:53: TypeError
device = 'cpu'

    def test_train_segmentation_rad_2d(device):
        print("03: Starting 2D Rad segmentation tests")
        # read and parse csv
        parameters = parseConfigGAN(
            testingDir + "/config_generation.yaml", version_check_flag=False
        )
        training_data, parameters["headers"] = parseTrainingCSV(
            inputDir + "/train_2d_rad_segmentation.csv"
        )
        parameters["modality"] = "rad"
        parameters["patch_size"] = patch_size["2D"]
        parameters["model"]["dimension"] = 2
        parameters["model"]["class_list"] = [0, 255]
        parameters["model"]["amp"] = True
        parameters["model"]["num_channels"] = 3
        parameters["model"]["onnx_export"] = False
        parameters["model"]["print_summary"] = False
        parameters["data_preprocessing"]["resize_image"] = [224, 224]
        parameters = populate_header_in_parameters(
            parameters, parameters["headers"]
        )
        # read and initialize parameters for specific data dimension
        for model in all_models_generation:
            parameters["model"]["architecture"] = model
            parameters["nested_training"]["testing"] = -5
            parameters["nested_training"]["validation"] = -5
            sanitize_outputDir()
>           TrainingManagerGAN(
                dataframe=training_data,
                outputDir=outputDir,
                parameters=parameters,
                device=device,
                resume=False,
                reset=True,
            )

GANDLF/GAN/testing/test_gan.py:80: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
../venvs/gandalf_env/lib/python3.10/site-packages/GANDLF/GAN/training_manager_gan.py:270: in TrainingManagerGAN
    training_loop_gans(
../venvs/gandalf_env/lib/python3.10/site-packages/GANDLF/GAN/compute/training_loop.py:511: in training_loop_gans
    ) = train_network_gan(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

model = DCGAN(
  (generator): _GneratorDCGAN(
    (feature_extractor): Sequential(
      (conv1t): ConvTranspose2d(100, 4, ker...nplace=True)
      (linear2): Linear(in_features=128, out_features=1, bias=True)
      (sigmoid): Sigmoid()
    )
  )
)
train_dataloader = <torch.utils.data.dataloader.DataLoader object at 0x7f15919af970>
optimizer_g = Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
  ...-08
    foreach: None
    fused: None
    initial_lr: 0.001
    lr: 0.001
    maximize: False
    weight_decay: 5e-05
)
optimizer_d = Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
  ...-08
    foreach: None
    fused: None
    initial_lr: 0.001
    lr: 0.001
    maximize: False
    weight_decay: 5e-05
)
params = {'batch_size': 1, 'bn_size': 4, 'channel_keys': ['1'], 'class_weights': None, ...}

    def train_network_gan(
        model, train_dataloader, optimizer_g, optimizer_d, params
    ):
        """
        Function to train a GAN network for a single epoch.
        This function is a modified version of train_network() to support
        usage of two optimizers for the generator and discriminator.
    
        Parameters
        ----------
        model : torch.model
            The model to process the input image with, it should support appropriate dimensions.
        train_dataloader : torch.DataLoader
            The dataloader for the training epoch
        optimizer_g : torch.optim
            Optimizer for optimizing generator network
        optimizer_d : torch.optim
            Optimizer for optimizing discriminator network
        params : dict
            the parameters passed by the user yaml
    
        Returns
        -------
        average_epoch_train_loss_gen : float
            Train loss for the current epoch for generator
        average_epoch_train_loss_disc : float
            Train loss for the current epoch for discriminator
        average_epoch_train_metric : dict
            Train metrics for the current epoch
        """
    
        print("*" * 20)
        print("Starting Training : ")
        print("*" * 20)
        # Initialize a few things
        total_epoch_train_loss_gen = 0
        total_epoch_train_loss_disc = 0
        total_epoch_train_metric = {}
        average_epoch_train_metric = {}
        for metric in params["metrics"]:
            if "per_label" in metric:  # conditional generation not yet implemented
                total_epoch_train_metric[metric] = []
            else:
                total_epoch_train_metric[metric] = 0
    
        # automatic mixed precision - https://pytorch.org/docs/stable/amp.html
        if params["model"]["amp"]:
            scaler = GradScaler()
            if params["verbose"]:
                print("Using Automatic mixed precision", flush=True)
    
        # Set the model to train
        model.train()
        for batch_idx, (subject) in enumerate(
            tqdm(train_dataloader, desc="Looping over training data")
        ):
            #### DISCRIMINATOR STEP WITH ALL REAL LABELS ####
            optimizer_d.zero_grad()
            image_real = (
                torch.cat(
                    [subject[key][torchio.DATA] for key in params["channel_keys"]],
                    dim=1,
                )
                .float()
                .to(params["device"])
            )
            current_batch_size = image_real.shape[0]
    
            label_real = torch.full(
                size=(current_batch_size,),
                fill_value=1,
                dtype=torch.float,
                device=params["device"],
            )
    
            if params["save_training"]:
                write_training_patches(
                    subject,
                    params,
                )
            # ensure spacing is always present in params and is always subject-specific
            if "spacing" in subject:
                params["subject_spacing"] = subject["spacing"]
            else:
                params["subject_spacing"] = None
            loss_disc_real, _, output_disc_real, _ = step_gan(
                model, image_real, label_real, params, secondary_images=None
            )
            nan_loss = torch.isnan(loss_disc_real)
            second_order = (
                hasattr(optimizer_d, "is_second_order")
                and optimizer_d.is_second_order
            )
            if params["model"]["amp"]:
                with torch.cuda.amp.autocast():
                    # if loss is nan, don't backprop and don't step optimizer
                    if not nan_loss:
                        scaler(
                            loss=loss_disc_real,
                            optimizer=optimizer_d,
                            clip_grad=params["clip_grad"],
                            clip_mode=params["clip_mode"],
                            parameters=model_parameters_exclude_head(
                                model, clip_mode=params["clip_mode"]
                            ),
                            create_graph=second_order,
                        )
            else:
                if not nan_loss:
                    loss_disc_real.backward(create_graph=second_order)
                    if params["clip_grad"] is not None:
                        dispatch_clip_grad_(
                            parameters=model_parameters_exclude_head(
                                model, clip_mode=params["clip_mode"]
                            ),
                            value=params["clip_grad"],
                            mode=params["clip_mode"],
                        )
    
            #### DISCRIMINATOR STEP WITH ALL FAKE LABELS ####
            latent_vector = torch.randn(
                current_batch_size,
>               params["model"]["latent_vector_size"],
                device=params["device"],
            )
E           KeyError: 'latent_vector_size'

../venvs/gandalf_env/lib/python3.10/site-packages/GANDLF/GAN/compute/training_loop.py:160: KeyError
device = 'cpu'

    def test_train_segmentation_rad_2d(device):
        print("03: Starting 2D Rad segmentation tests")
        # read and parse csv
        parameters = parseConfigGAN(
            testingDir + "/config_generation.yaml", version_check_flag=False
        )
        training_data, parameters["headers"] = parseTrainingCSV(
            inputDir + "/train_2d_rad_segmentation.csv"
        )
        parameters["modality"] = "rad"
        parameters["patch_size"] = patch_size["2D"]
        parameters["model"]["dimension"] = 2
        parameters["model"]["class_list"] = [0, 255]
        parameters["model"]["amp"] = True
        parameters["model"]["num_channels"] = 3
        parameters["model"]["onnx_export"] = False
        parameters["model"]["print_summary"] = False
        parameters["data_preprocessing"]["resize_image"] = [224, 224]
        parameters = populate_header_in_parameters(
            parameters, parameters["headers"]
        )
        # read and initialize parameters for specific data dimension
        for model in all_models_generation:
            parameters["model"]["architecture"] = model
            parameters["nested_training"]["testing"] = -5
            parameters["nested_training"]["validation"] = -5
            sanitize_outputDir()
>           TrainingManagerGAN(
                dataframe=training_data,
                outputDir=outputDir,
                parameters=parameters,
                device=device,
                resume=False,
                reset=True,
            )

GANDLF/GAN/testing/test_gan.py:80: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
../venvs/gandalf_env/lib/python3.10/site-packages/GANDLF/GAN/training_manager_gan.py:270: in TrainingManagerGAN
    training_loop_gans(
../venvs/gandalf_env/lib/python3.10/site-packages/GANDLF/GAN/compute/training_loop.py:511: in training_loop_gans
    ) = train_network_gan(
../venvs/gandalf_env/lib/python3.10/site-packages/GANDLF/GAN/compute/training_loop.py:164: in train_network_gan
    fake_images = model.generator(latent_vector)
../venvs/gandalf_env/lib/python3.10/site-packages/torch/nn/modules/module.py:1518: in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
../venvs/gandalf_env/lib/python3.10/site-packages/torch/nn/modules/module.py:1527: in _call_impl
    return forward_call(*args, **kwargs)
../venvs/gandalf_env/lib/python3.10/site-packages/GANDLF/models/dcgan.py:178: in forward
    out = self.feature_extractor(x)
../venvs/gandalf_env/lib/python3.10/site-packages/torch/nn/modules/module.py:1518: in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
../venvs/gandalf_env/lib/python3.10/site-packages/torch/nn/modules/module.py:1527: in _call_impl
    return forward_call(*args, **kwargs)
../venvs/gandalf_env/lib/python3.10/site-packages/torch/nn/modules/container.py:215: in forward
    input = module(input)
../venvs/gandalf_env/lib/python3.10/site-packages/torch/nn/modules/module.py:1518: in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
../venvs/gandalf_env/lib/python3.10/site-packages/torch/nn/modules/module.py:1527: in _call_impl
    return forward_call(*args, **kwargs)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = ConvTranspose2d(100, 4, kernel_size=(4, 4), stride=(1, 1), bias=False)
input = tensor([[ 0.6329,  1.6758,  0.7465,  0.2742,  0.3970,  0.7624,  1.4102, -0.4160,
          2.5015,  1.1939,  1.2833, -... -0.5962,  0.2316, -0.7123,  0.3340, -1.2913,  1.1229, -0.4159, -1.2324,
         -0.5949,  1.1005, -0.1164,  0.9811]])
output_size = None

    def forward(self, input: Tensor, output_size: Optional[List[int]] = None) -> Tensor:
        if self.padding_mode != 'zeros':
            raise ValueError('Only `zeros` padding mode is supported for ConvTranspose2d')
    
        assert isinstance(self.padding, tuple)
        # One cannot replace List by Tuple or Sequence in "_output_padding" because
        # TorchScript does not support `Sequence[T]` or `Tuple[T, ...]`.
        num_spatial_dims = 2
        output_padding = self._output_padding(
            input, output_size, self.stride, self.padding, self.kernel_size,  # type: ignore[arg-type]
            num_spatial_dims, self.dilation)  # type: ignore[arg-type]
    
>       return F.conv_transpose2d(
            input, self.weight, self.bias, self.stride, self.padding,
            output_padding, self.groups, self.dilation)
E       RuntimeError: Expected 3D (unbatched) or 4D (batched) input to conv_transpose2d, but got input of size: [1, 100]

../venvs/gandalf_env/lib/python3.10/site-packages/torch/nn/modules/conv.py:952: RuntimeError
