import torch


# Dice scores and dice losses
def dice(output, target):
    """
    This function computes a dice score between two tensors

    Parameters
    ----------
    output : Tensor
        Output predicted generally by the network
    target : Tensor
        Required target label to match the output with

    Returns
    -------
    Tensor
        Computed Dice Score

    """
    smooth = 1e-7

    output_flat = output.contiguous().view(-1)
    label_flat = target.contiguous().view(-1)
    intersection = (output_flat * label_flat).sum()

    dice_score = (2.0 * intersection + smooth) / (
        output_flat.sum() + label_flat.sum() + smooth
    )

    return dice_score


def MCD(output, target, num_class, weights=None, ignore_class=None, loss_type=0):
    """
    Parameters
    ----------
    output : torch.Tensor
        Prediction tensor generated by the model
    tarrget : torch.Tensor
        Ground truth tensor
    num_class : int
        Number of classes (including the background class)
    weights : list, optional
        Dice weights for each class (excluding the background class), defaults to None
    ignore_class : int, optional
        Class to ignore, defaults to None
    loss_type : int, optional
        Type of loss to compute, defaults to 0
        0: no loss, normal dice calculation
        1: dice loss, (1-dice)
        2: log dice, -log(dice)

    Returns
    -------
    Tensor
        Mean Class Dice score
    """

    acc_dice = 0

    for i in range(num_class):  # 0 is background
        if ignore_class is not None and i == ignore_class:
            continue  # ignore the specified class

        currentDice = dice(output[:, i, ...], target[:, i, ...])

        if loss_type == 1:
            currentDice = 1 - currentDice  # subtract from 1 because this is a loss
        elif loss_type == 2:
            currentDice = -torch.log(
                currentDice + torch.finfo(torch.float32).eps
            )  # negative because we want positive losses

        if weights is not None:
            currentDice = currentDice * weights[i]  # multiply by weight

        acc_dice += currentDice

    if weights is None:
        acc_dice /= num_class  # we should not be considering 0

    return acc_dice


def MCD_loss(pm, gt, params):
    """
    These weights should be the penalty weights, not dice weights
    """
    return MCD(pm, gt, len(params["model"]["class_list"]), params["weights"], None, 1)


def MCD_log_loss(pm, gt, params):
    """
    These weights should be the penalty weights, not dice weights
    """
    return MCD(pm, gt, len(params["model"]["class_list"]), params["weights"], None, 2)


def tversky_loss(output, target, alpha=0.5, beta=0.5, smooth=1e-7):
    """
    This function calculates the Tversky loss between two tensors.

    Parameters
    ----------
    output : torch.Tensor
        Output predicted generally by the network
    target : torch.Tensor
        Required target label to match the output with
    alpha : float, optional
        Weight of false positives
    beta : float, optional
        Weight of false negatives
    smooth : float, optional
        Smoothing factor to avoid division by zero

    Returns
    -------
    torch.Tensor
        Computed Tversky Loss

    """
    # Move this part later to parameter parsing, no need to check every time
    if not 0 <= alpha <= 1:
        raise ValueError(f"Invalid alpha value: {alpha}")
    if not 0 <= beta <= 1:
        raise ValueError(f"Invalid beta value: {beta}")
    if not 0 <= alpha + beta <= 1:
        raise ValueError(f"Invalid alpha and beta values: {alpha}, {beta}")

    output_flat = output.contiguous().view(-1)
    target_flat = target.contiguous().view(-1)

    true_positives = (output_flat * target_flat).sum()
    false_positives = ((1 - target_flat) * output_flat).sum()
    false_negatives = (target_flat * (1 - output_flat)).sum()

    numerator = true_positives
    denominator = true_positives + alpha * false_positives + beta * false_negatives
    score = (numerator + smooth) / (denominator + smooth)

    loss = 1 - score
    return loss


def MCT_loss(inp, target, params=None):
    """
    This function calculates the Multi-Class Tversky loss between two tensors.

    Parameters
    ----------
    inp : torch.Tensor
        Output predicted generally by the network
    target : torch.Tensor
        Required target label to match the output with
    params : dict, optional
        Additional parameters for computing loss function, including weights for each class

    Returns
    -------
    torch.Tensor
        Computed Multi-Class Tversky Loss

    """

    acc_tv_loss = 0
    num_classes = inp.shape[1]

    for i in range(num_classes):
        curr_loss = tversky_loss(inp[:, i, ...], target[:, i, ...])
        if params is not None and params.get("weights") is not None:
            curr_loss = curr_loss * params["weights"][i]
        acc_tv_loss += curr_loss

    if params is not None and params.get("weights") is None:
        acc_tv_loss /= num_classes

    return acc_tv_loss


def KullbackLeiblerDivergence(mu, logvar, params=None):
    loss = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp(), dim=-1)
    return loss.mean()
