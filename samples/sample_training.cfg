# Choose the segmentation model here 
# options: unet, resunet, fcn
modelName = resunet
# Set base filters: number of filters present in the initial module of the U-Net convolution; for IncU-Net, keep this divisible by 4
base_filters = 30
# Set the largest label the model should predict
# for example, for BraTS, this should be 4, even though 3 is not present
# any label that is absent (for instance, '3' for BraTS) is not trained on
largestLabelToPredict = 4
# Number of channels/modalities - we shall use this as sanity check when we read the train.csv or test.csv
numberOfInputChannels = 3
# Patch size during training - 2D patch for breast images since third dimension is not patched 
patch_size = [128,128,128]
# Number of epochs
num_epochs = 500
# Set the batch size
batch_size = 1
# Set the initial learning rate
learning_rate = 1
# Set which loss function you want to use - options : 'dc' - for dice only, 'dcce' - for sum of dice and CE and you can guess the next (only lower-case please)
# options: dc (dice only), ce (), dcce (sume of dice and ce), mse (), ...
loss_function = dc
# Which optimizer do you want to use - adam/sgd
opt = adam
# How many best models to save
save_best = 5
# the value of 'k' for cross-validation, this is the percentage of total training data to use as validation;
# randomized split is performed using sklearn's KFold method
# for single fold run, use '-' before the fold number
kcross_validation = 10
# various data augmentation techniques
# options: affine, elastic, downsample, motion, ghosting, bias, blur, gaussianNoise, swap
# keep/edit as needed
# all transforms: https://torchio.readthedocs.io/transforms/transforms.html?highlight=transforms
# 'normalize': performs z-score normalization: https://torchio.readthedocs.io/transforms/preprocessing.html?highlight=ToCanonical#torchio.transforms.ZNormalization
# 'resample:X,Y,Z': resample the voxel resolution: https://torchio.readthedocs.io/transforms/preprocessing.html?highlight=ToCanonical#torchio.transforms.Resample
data_augmentation = ['normalize', 'resample:1,2,3', 'affine', 'elastic', 'motion', 'ghosting', 'bias', 'blur', 'noise', 'swap']
# parallel training on HPC - here goes the command to prepend to send to a high performance computing
# cluster for parallel computing during multi-fold training
# not used for single fold training
# this gets passed before the training_loop, so ensure enough memory is provided along with other parameters
# that your HPC would expect
# ${outputDir} will be changed to the outputDir you pass in CLI + '/${fold_number}'
# ensure that the correct location of the virtual environment is getting invoked, otherwise it would pick up the system python, which might not have all dependencies
parallel_compute_command = '`pwd`/sge_wrapper qsub -b y -l gpu -l h_vmem=32G -cwd -o ${outputDir}/$JOB_ID.stdout -e ${outputDir}/$JOB_ID.stderr _correct_location_of_virtual_environment_/venv/bin/python'
